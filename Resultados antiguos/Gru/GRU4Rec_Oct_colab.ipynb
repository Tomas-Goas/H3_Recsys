{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9RQZRGYjoKS"
      },
      "source": [
        "# Notebook GRU4Rec sin Dwell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quuledn3tOSc",
        "outputId": "d8ef8949-9d2e-4ea0-e2bb-f86343816b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mkechinov/ecommerce-behavior-data-from-multi-category-store?dataset_version_number=8...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.29G/4.29G [00:25<00:00, 182MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store/versions/8\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mkechinov/ecommerce-behavior-data-from-multi-category-store\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w3IJIPMv2StQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "path = \"/root/.cache/kagglehub/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store/versions/8\"\n",
        "\n",
        "USE_COLS = [\"event_time\", \"user_id\", \"product_id\", \"user_session\"]\n",
        "\n",
        "def reduce_month(month_filename, output_filename, chunksize=1_000_000):\n",
        "\n",
        "    reader = pd.read_csv(\n",
        "        f\"{path}/{month_filename}\",\n",
        "        usecols=USE_COLS,\n",
        "        chunksize=chunksize\n",
        "    )\n",
        "\n",
        "    first = True\n",
        "\n",
        "    for chunk in reader:\n",
        "        # Convertir fechas dentro del chunk\n",
        "        chunk[\"event_time\"] = pd.to_datetime(chunk[\"event_time\"])\n",
        "\n",
        "        # Guardar chunk reducido\n",
        "        chunk.to_csv(output_filename, mode=\"w\" if first else \"a\",\n",
        "                     index=False, header=first)\n",
        "        first = False\n",
        "\n",
        "        del chunk\n",
        "        gc.collect()\n",
        "\n",
        "    print(\"OUTPUT creado:\", output_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12C0eWhl4v4r",
        "outputId": "5f6a8e7a-d4b9-4a98-f43b-954572fba6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OUTPUT creado: oct_reduced.csv\n",
            "OUTPUT creado: nov_reduced.csv\n"
          ]
        }
      ],
      "source": [
        "reduce_month(\"2019-Oct.csv\", \"oct_reduced.csv\")\n",
        "reduce_month(\"2019-Nov.csv\", \"nov_reduced.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AC0H8q0v5OAP"
      },
      "outputs": [],
      "source": [
        "oct = pd.read_csv(\"oct_reduced.csv\")\n",
        "#nov = pd.read_csv(\"nov_reduced.csv\")\n",
        "\n",
        "# evento_time como datetime\n",
        "oct[\"event_time\"] = pd.to_datetime(oct[\"event_time\"])\n",
        "#nov[\"event_time\"] = pd.to_datetime(nov[\"event_time\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hhui51GS3lgF"
      },
      "outputs": [],
      "source": [
        "def split_train_test(df):\n",
        "\n",
        "    df = df.sort_values(\"event_time\")\n",
        "    cutoff = df[\"event_time\"].quantile(0.9)\n",
        "\n",
        "    train = df[df[\"event_time\"] < cutoff]\n",
        "    test  = df[df[\"event_time\"] >= cutoff]\n",
        "\n",
        "    return train, test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PeqdOELNHn-",
        "outputId": "2354934f-4e49-43a5-f0a1-533a549af39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38203886 4244878\n"
          ]
        }
      ],
      "source": [
        "oct_train, oct_test = split_train_test(oct)\n",
        "print(len(oct_train), len(oct_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inxPNQPENNag"
      },
      "outputs": [],
      "source": [
        "#nov_train, nov_test = split_train_test(nov)\n",
        "#print(len(nov_train), len(nov_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w_NkEURzOtJ4"
      },
      "outputs": [],
      "source": [
        "def build_sessions(df):\n",
        "    df = df.sort_values([\"user_session\", \"event_time\"])\n",
        "    sessions = df.groupby(\"user_session\")[\"product_id\"].apply(list)\n",
        "    return sessions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BtvurIj2OuTU"
      },
      "outputs": [],
      "source": [
        "oct_train_sessions = build_sessions(oct_train)\n",
        "oct_test_sessions  = build_sessions(oct_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7JKYO96XTRZ3"
      },
      "outputs": [],
      "source": [
        "def filter_sessions_min_length(sessions, min_len=5):\n",
        "    return sessions[sessions.apply(len) >= min_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TyEWYkdLTSqT"
      },
      "outputs": [],
      "source": [
        "oct_train_sessions = filter_sessions_min_length(oct_train_sessions, min_len=5)\n",
        "oct_test_sessions  = filter_sessions_min_length(oct_test_sessions,  min_len=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7J-ErRXaO1Th"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def build_id_maps(train_sessions):\n",
        "    all_items = set()\n",
        "    for s in train_sessions:\n",
        "        all_items.update(s)\n",
        "\n",
        "    item2idx = {item: i+1 for i, item in enumerate(all_items)}\n",
        "    idx2item = {i+1: item for i, item in enumerate(all_items)}\n",
        "\n",
        "    return item2idx, idx2item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "i1Zw2zxjPaKT"
      },
      "outputs": [],
      "source": [
        "item2idx, idx2item = build_id_maps(oct_train_sessions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A_ZMi88wPdK5"
      },
      "outputs": [],
      "source": [
        "def encode_sessions(sessions, item2idx, min_len=5):\n",
        "    encoded = []\n",
        "    for seq in sessions:\n",
        "        seq = [item2idx[x] for x in seq if x in item2idx]\n",
        "        if len(seq) >= min_len:\n",
        "            encoded.append(seq)\n",
        "    return encoded\n",
        "\n",
        "train_encoded = encode_sessions(oct_train_sessions, item2idx)\n",
        "test_encoded  = encode_sessions(oct_test_sessions, item2idx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAHDk6UMc09R"
      },
      "source": [
        "### Modelo GRU sin Dwell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "htGmAq8JPeoM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "MAX_LEN = 100\n",
        "\n",
        "class GRUDataset(Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.sequences[idx]\n",
        "        if len(seq) > MAX_LEN:\n",
        "            seq = seq[-MAX_LEN:]   # conservar las últimas interacciones\n",
        "        return torch.tensor(seq[:-1]), torch.tensor(seq[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MgZn497-ST3O"
      },
      "outputs": [],
      "source": [
        "PAD_IDX = 0\n",
        "\n",
        "def collate_fn(batch):\n",
        "    X_batch, y_batch = zip(*batch)\n",
        "\n",
        "    # Longitudes individuales\n",
        "    lengths = [len(x) for x in X_batch]\n",
        "    max_len = max(lengths)\n",
        "\n",
        "    # Pading\n",
        "    X_padded = [torch.cat([x, torch.full((max_len - len(x),), PAD_IDX)]) for x in X_batch]\n",
        "    y_padded = [torch.cat([y, torch.full((max_len - len(y),), PAD_IDX)]) for y in y_batch]\n",
        "\n",
        "    return torch.stack(X_padded), torch.stack(y_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xcOVFeERPgKL"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    GRUDataset(train_encoded),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    GRUDataset(test_encoded),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B7-1bpX8Phu6"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GRU4Rec(nn.Module):\n",
        "    def __init__(self, n_items, emb_size=128, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(n_items+1, emb_size)\n",
        "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, n_items+1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        out, _ = self.gru(x)\n",
        "        logits = self.fc(out)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9DVEc4HnPjGo"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "n_items = len(item2idx)\n",
        "model = GRU4Rec(n_items).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UEy3rSekPkc8"
      },
      "outputs": [],
      "source": [
        "def train_gru(model, loader, optimizer, criterion, epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        total_loss = 0\n",
        "\n",
        "        for X, y in loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits = model(X)\n",
        "\n",
        "            logits = logits.reshape(-1, logits.size(-1))\n",
        "            y = y.reshape(-1)\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"[Epoch {epoch}] Loss = {total_loss/len(loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1UsWqJ6SCr3",
        "outputId": "5267e526-09f1-47fa-c4ff-2defa2968d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1] Loss = 5.3946\n",
            "[Epoch 2] Loss = 4.7251\n",
            "[Epoch 3] Loss = 4.5912\n",
            "[Epoch 4] Loss = 4.5242\n",
            "[Epoch 5] Loss = 4.4851\n",
            "[Epoch 6] Loss = 4.4573\n",
            "[Epoch 7] Loss = 4.4373\n",
            "[Epoch 8] Loss = 4.4204\n",
            "[Epoch 9] Loss = 4.4078\n",
            "[Epoch 10] Loss = 4.3979\n"
          ]
        }
      ],
      "source": [
        "train_gru(model, train_loader, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KW3tEuNuPmHV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def recall_at_k(pred, target, k=10):\n",
        "    return 1.0 if target in pred[:k] else 0.0\n",
        "\n",
        "def ndcg_at_k(pred, target, k=10):\n",
        "    if target in pred[:k]:\n",
        "        idx = pred[:k].index(target)\n",
        "        return 1 / np.log2(idx + 2)\n",
        "    return 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZviQ6E5Po52",
        "outputId": "2fff732f-b644-459f-e077-ed14ee04168a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall@10: 0.5706841180391444\n",
            "NDCG@10: 0.4560607495303335\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "rec_list = []\n",
        "ndcg_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "        X = X.to(device)\n",
        "        logits = model(X)\n",
        "\n",
        "        # último paso predice el próximo item\n",
        "        last_logits = logits[0, -1]\n",
        "        topk = torch.topk(last_logits, 10).indices.cpu().tolist()\n",
        "\n",
        "        true_item = y[0, -1].item()\n",
        "\n",
        "        rec_list.append(recall_at_k(topk, true_item))\n",
        "        ndcg_list.append(ndcg_at_k(topk, true_item))\n",
        "\n",
        "recall10 = np.mean(rec_list)\n",
        "ndcg10 = np.mean(ndcg_list)\n",
        "\n",
        "print(\"Recall@10:\", recall10)\n",
        "print(\"NDCG@10:\", ndcg10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
