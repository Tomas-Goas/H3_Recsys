# Impacto del Dwell Time en Recomendaci칩n Secuencial  
**Autores:** Tom치s Goas, Leopoldo Farr  
**Instituci칩n:** Pontificia Universidad Cat칩lica de Chile  

---

## Resumen del estudio

Este repositorio contiene los experimentos, modelos y c칩digo utilizados para analizar el **impacto del dwell time** en el rendimiento de distintos algoritmos de **recomendaci칩n secuencial**.

El *dwell time* se incorpora repitiendo un 칤tem dentro de la secuencia un n칰mero de veces proporcional al tiempo que el usuario lo visualiza. Esto convierte el inter칠s del usuario en una se침al expl칤cita dentro del modelo, pero al mismo tiempo **alarga artificialmente las sesiones**, lo que incrementa los tiempos de entrenamiento y modifica la distribuci칩n de secuencias.

El estudio compara modelos **con** y **sin** dwell, evaluando c칩mo la arquitectura influye en su capacidad para aprovechar esta se침al.

---

## 游늵 Modelos evaluados

### **GRU4Rec**
Modelo recurrente basado en GRUs que captura dependencias de corto plazo a trav칠s de un estado oculto.  
El dwell act칰a como una forma natural de refuerzo dentro de la din치mica recurrente.

### **BERT4Rec**
Transformer bidireccional entrenado mediante *masked item prediction*.  
La repetici칩n producida por dwell introduce ruido contextual y degrada el rendimiento en forma consistente.

### **SASRec**
Modelo Transformer **causal/unidireccional**.  
Aprovecha la atenci칩n como BERT, pero sin romper la direccionalidad. El dwell se incorpora como una se침al temporal v치lida.

### **NARM (Neural Attentive Session Model)**
Modelo h칤brido que combina GRU + atenci칩n sobre el contexto.  
Es el que **m치s se beneficia** del dwell: la atenci칩n amplifica se침ales repetidas interpret치ndolas como evidencia expl칤cita de inter칠s.

---

## 游늳 Principales resultados

- El dwell time **no es universalmente beneficioso**: depende fuertemente de la arquitectura.  
- Modelos **causales** (GRU4Rec, SASRec, NARM) mejoran significativamente.  
- Modelos **bidireccionales** (BERT4Rec) se degradan por ruido contextual.  
- **NARM** presenta las mejoras m치s grandes entre todos los modelos.  
- El dwell genera **sesiones m치s largas**, mayor costo computacional y diferencias en tiempos de entrenamiento.  
  - En noviembre, curiosamente, el entrenamiento **sin dwell fue ~20% m치s lento**, posiblemente por mayor variabilidad en longitudes, batching menos eficiente o mayor dispersi칩n en las sesiones.

---

## 丘뙖잺 Datasets

Los experimentos usan datasets p칰blicos del proyecto **Open CDP (Rees46 Technologies)**, correspondientes a:

- Octubre 2019  
- Noviembre 2019  

Cada registro representa un evento asociado a un producto en un e-commerce multicategor칤a (views, cart, purchase).

